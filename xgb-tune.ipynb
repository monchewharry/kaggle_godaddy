{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# within train set tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>cfips</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>first_day_of_month</th>\n",
       "      <th>microbusiness_density</th>\n",
       "      <th>active</th>\n",
       "      <th>istest</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>lastactive</th>\n",
       "      <th>lasttarget</th>\n",
       "      <th>act_lag_1</th>\n",
       "      <th>mbd_lag_2</th>\n",
       "      <th>act_lag_2</th>\n",
       "      <th>mbd_lag_3</th>\n",
       "      <th>act_lag_3</th>\n",
       "      <th>mbd_rollmea2_1</th>\n",
       "      <th>mbd_rollmea4_1</th>\n",
       "      <th>mbd_rollmea6_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001_2019-08-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>2.856021</td>\n",
       "      <td>1249.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>3.286307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001_2019-09-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2.884870</td>\n",
       "      <td>1198.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>3.286307</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.010101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001_2019-10-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>3.055843</td>\n",
       "      <td>1269.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>3.286307</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.069366</td>\n",
       "      <td>0.069366</td>\n",
       "      <td>0.069366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001_2019-11-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>2.993233</td>\n",
       "      <td>1243.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>3.286307</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>0.059265</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0.038777</td>\n",
       "      <td>0.048878</td>\n",
       "      <td>0.048878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001_2019-12-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2.993233</td>\n",
       "      <td>1243.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>3.286307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.020489</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>0.059265</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-0.020489</td>\n",
       "      <td>0.048878</td>\n",
       "      <td>0.048878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id  cfips          county    state first_day_of_month  \\\n",
       "0  1001_2019-08-01   1001  Autauga County  Alabama         2019-08-01   \n",
       "1  1001_2019-09-01   1001  Autauga County  Alabama         2019-09-01   \n",
       "2  1001_2019-10-01   1001  Autauga County  Alabama         2019-10-01   \n",
       "3  1001_2019-11-01   1001  Autauga County  Alabama         2019-11-01   \n",
       "4  1001_2019-12-01   1001  Autauga County  Alabama         2019-12-01   \n",
       "\n",
       "   microbusiness_density  active  istest  year  month  ...  lastactive  \\\n",
       "0               2.856021  1249.0       0  2019      8  ...      1472.0   \n",
       "1               2.884870  1198.0       0  2019      9  ...      1472.0   \n",
       "2               3.055843  1269.0       0  2019     10  ...      1472.0   \n",
       "3               2.993233  1243.0       0  2019     11  ...      1472.0   \n",
       "4               2.993233  1243.0       0  2019     12  ...      1472.0   \n",
       "\n",
       "   lasttarget  act_lag_1  mbd_lag_2  act_lag_2  mbd_lag_3  act_lag_3  \\\n",
       "0    3.286307        NaN        NaN        NaN        NaN        NaN   \n",
       "1    3.286307      -51.0        NaN        NaN        NaN        NaN   \n",
       "2    3.286307       71.0   0.010101       20.0        NaN        NaN   \n",
       "3    3.286307      -26.0   0.059265       45.0   0.010101       -6.0   \n",
       "4    3.286307        0.0  -0.020489      -26.0   0.059265       45.0   \n",
       "\n",
       "   mbd_rollmea2_1  mbd_rollmea4_1  mbd_rollmea6_1  \n",
       "0             NaN             NaN             NaN  \n",
       "1        0.010101        0.010101        0.010101  \n",
       "2        0.069366        0.069366        0.069366  \n",
       "3        0.038777        0.048878        0.048878  \n",
       "4       -0.020489        0.048878        0.048878  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from godaddy_utility import *\n",
    "from sklearn.model_selection import ParameterGrid,ParameterSampler\n",
    "import os\n",
    "from random import sample\n",
    "from os.path import exists\n",
    "import json\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "raw = pd.read_csv('./input/raw.csv')\n",
    "raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous version: 0\n",
      "current saving version: 1\n"
     ]
    }
   ],
   "source": [
    "PRE_MOD_FOLDER = \"./trainedXGB\"\n",
    "if os.listdir(PRE_MOD_FOLDER) == []:\n",
    "    previous_version = 0\n",
    "else:\n",
    "    previous_version = sorted([int(s.split('_')[-1]) for s in os.listdir(PRE_MOD_FOLDER) \\\n",
    "                           if 'model_nof' in s])[-1]\n",
    "params_version=previous_version+1\n",
    "\n",
    "print(f\"Previous version: {previous_version}\")\n",
    "print(f\"current saving version: {params_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make folder is not exist\n",
    "os.system(f\"mkdir -p {PRE_MOD_FOLDER}/model_nof_{params_version}\")\n",
    "#write necessary notes: check end of the notebook\n",
    "with open(f'{PRE_MOD_FOLDER}/model_nof_{params_version}/README{params_version}.txt', 'w') as f:\n",
    "    f.write(f'Version {params_version}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tune settings made\n"
     ]
    }
   ],
   "source": [
    "tunepara = True  #params_xgb\n",
    "num_pset = 300\n",
    "tunefeatures=True #feature_params\n",
    "num_fset = 80\n",
    "justretrain = False\n",
    "\n",
    "#################################################################xgb hyperparameters\n",
    "if exists(PRE_MOD_FOLDER+f\"/model_nof_{previous_version}/skipping_pre_next{previous_version}\"):\n",
    "    with open(PRE_MOD_FOLDER+f\"/model_nof_{previous_version}/skipping_pre_next{previous_version}\",'rb') as fp:\n",
    "        #if new feature_prebest set to False\n",
    "        skipping_pre = pickle.load(fp)\n",
    "else:\n",
    "    skipping_pre = False\n",
    "\n",
    "if exists(PRE_MOD_FOLDER+f\"/model_nof_{previous_version}/params_xgb_best{previous_version}\"):\n",
    "    with open(PRE_MOD_FOLDER+f\"/model_nof_{previous_version}/params_xgb_best{previous_version}\", 'rb') as f: \n",
    "        params_xgb_prebest = pickle.load(f)\n",
    "else:\n",
    "    params_xgb_prebest = None\n",
    "\n",
    "if exists(PRE_MOD_FOLDER+f\"/model_nof_{previous_version}/params_xgb_score{previous_version}\"):\n",
    "    with open(PRE_MOD_FOLDER+f\"/model_nof_{previous_version}/params_xgb_score{previous_version}\", \"rb\") as fp:   \n",
    "        params_xgb_prescore = pickle.load(fp)\n",
    "else: \n",
    "    params_xgb_prescore = []\n",
    "\n",
    "if skipping_pre==False:\n",
    "    params_xgb_prescore = []\n",
    "\n",
    "\n",
    "#################################################################feature parameterss\n",
    "skipping_pre_feature = False #placeholder, depending on the new params_xgb\n",
    "\n",
    "if exists(PRE_MOD_FOLDER+f\"/model_nof_{previous_version}/feature_best{previous_version}\"):\n",
    "    with open(PRE_MOD_FOLDER+f\"/model_nof_{previous_version}/feature_best{previous_version}\", \"rb\") as fp:\n",
    "        feature_prebest = pickle.load(fp)\n",
    "else:\n",
    "    feature_prebest = None\n",
    "\n",
    "if exists(PRE_MOD_FOLDER+f\"/model_nof_{previous_version}/feature_score{previous_version}\"):\n",
    "    with open(PRE_MOD_FOLDER+f\"/model_nof_{previous_version}/feature_score{previous_version}\", \"rb\") as fp:   \n",
    "        feature_prescore = pickle.load(fp)\n",
    "        pre_score = feature_prescore[-1][0]\n",
    "else:\n",
    "    feature_prescore = []\n",
    "    pre_score = None\n",
    "    \n",
    "\n",
    "\n",
    "if justretrain:\n",
    "    feature_prescore = []\n",
    "    params_xgb_prescore = []\n",
    "    \n",
    "print('tune settings made')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb_prebest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_prebest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## black list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = [\n",
    "    'North Dakota', 'Iowa', 'Kansas', 'Nebraska', 'South Dakota','New Mexico', 'Alaska', 'Vermont'\n",
    "]\n",
    "blacklistcfips = [\n",
    "1019,1027,1029,1035,1039,1045,1049,1057,1067,1071,1077,1085,1091,1099,1101,1123,1131,1133,4001,4012,4013,4021,4023,5001,5003,5005,5017,5019,5027,5031,5035,5047,5063,5065,5071,5081,5083,5087,5091,5093,5107,5109,5115,5121,5137,5139,5141,5147,6003,6015,6027,6033,6053,6055,6057,6071,6093,6097,6103,6105,6115,8003,8007,8009,8019,8021,8023,8047,8051,8053,8055,8057,8059,8061,8065,8067,8069,8071,8073,8075,8085,8091,8093,8097,8099,8103,8105,8107,8109,8111,8115,8117,8121,9007,9009,9015,12009,12017,12019,12029,12047,12055,12065,12075,12093,12107,12127,13005,13007,13015,13017,13019,13027,13035,13047,13065,13081,13083,13099,13107,13109,13117,13119,13121,13123,13125,13127,13135,13143,13147,13161,13165,13171,13175,13181,13193,13201,13221,13225,13229,13231,13233,13245,13247,13249,13257,13279,13281,13287,13289,13293,13301,13319,15001,15005,15007,16001,16003,16005,16007,16013,16015,16017,16023,16025,16029,16031,16033,16035,16037,16043,16045,16049,16061,16063,16067,17001,17003,17007,17009,17013,17015,17023,17025,17031,17035,17045,17051,17059,17061,17063,17065,17067,17069,17075,17077,17081,17085,17087,17103,17105,17107,17109,17115,17117,17123,17127,17133,17137,17141,17143,17147,17153,17167,17169,17171,17177,17179,17181,17185,17187,17193,18001,18007,18009,18013,18015,18019,18021,18025,18035,18037,18039,18041,18053,18061,18075,18079,18083,18087,18099,18103,18111,18113,18115,18137,18139,18145,18153,18171,18179,21001,21003,21013,21017,21023,21029,21035,21037,21039,21045,21047,21055,21059,21065,21075,21077,21085,21091,21093,21097,21099,21101,21103,21115,21125,21137,21139,21141,21149,21155,21157,21161,21165,21179,21183,21191,21197,21199,21215,21217,21223,21227,21237,21239,22019,22021,22031,22039,22041,22047,22069,22085,22089,22101,22103,22109,22111,22115,22119,22121,23003,23009,23021,23027,23029,24011,24027,24029,24031,24035,24037,24039,24041,25011,25015,26003,26007,26011,26019,26021,26025,26027,26033,26037,26041,26043,26051,26053,26057,26059,26061,26065,26071,26077,26079,26083,26089,26097,26101,26103,26109,26111,26115,26117,26119,26127,26129,26131,26135,26141,26143,26155,26161,26165,27005,27011,27013,27015,27017,27021,27023,27025,27029,27047,27051,27055,27057,27065,27069,27073,27075,27077,27079,27087,27091,27095,27101,27103,27105,27107,27109,27113,27117,27119,27123,27125,27129,27131,27133,27135,27141,27147,27149,27155,27159,27167,27169,28017,28019,28023,28025,28035,28045,28049,28061,28063,28093,28097,28099,28125,28137,28139,28147,28159,29001,29015,29019,29031,29033,29041,29049,29051,29055,29057,29063,29065,29069,29075,29085,29089,29101,29103,29111,29121,29123,29125,29135,29137,29139,29143,29157,29159,29161,29167,29171,29173,29175,29177,29183,29195,29197,29199,29203,29205,29207,29209,29213,29215,29217,29223,29227,29229,30005,30009,30025,30027,30033,30035,30037,30039,30045,30049,30051,30053,30055,30057,30059,30069,30071,30073,30077,30079,30083,30085,30089,30091,30093,30101,30103,30105,30107,30109,32005,32009,32017,32023,32027,32029,32510,33005,33007,34021,34027,34033,34035,36011,36017,36023,36033,36043,36047,36049,36051,36057,36061,36067,36083,36091,36097,36103,36107,36113,36115,36121,36123,37005,37009,37011,37017,37023,37029,37031,37049,37061,37075,37095,37117,37123,37131,37137,37151,37187,37189,37197,39005,39009,39015,39017,39019,39023,39037,39039,39043,39049,39053,39057,39063,39067,39071,39077,39085,39087,39091,39097,39105,39107,39113,39117,39119,39125,39127,39129,39135,39137,39151,39153,39157,40003,40013,40015,40023,40025,40027,40035,40039,40043,40045,40053,40055,40057,40059,40065,40067,40073,40077,40079,40099,40105,40107,40111,40115,40123,40127,40129,40133,40141,40147,40151,40153,41001,41007,41013,41015,41017,41021,41025,41031,41033,41037,41051,41055,41063,41067,41069,42005,42007,42011,42013,42015,42019,42027,42029,42031,42035,42053,42057,42067,42071,42083,42085,42093,42097,42105,42111,42113,42115,42123,42125,42127,42129,44005,44007,44009,45001,45009,45021,45025,45031,45059,45067,45071,45073,45089,47001,47005,47013,47015,47019,47021,47023,47027,47035,47039,47041,47047,47055,47057,47059,47061,47069,47073,47075,47077,47083,47087,47099,47105,47121,47127,47131,47133,47135,47137,47147,47151,47153,47159,47161,47163,47169,47177,47183,47185,48001,48011,48017,48019,48045,48057,48059,48063,48065,48073,48077,48079,48081,48083,48087,48095,48101,48103,48107,48109,48115,48117,48119,48123,48125,48129,48149,48151,48153,48155,48159,48161,48165,48175,48189,48191,48195,48197,48211,48221,48229,48233,48235,48237,48239,48241,48243,48245,48255,48261,48263,48265,48267,48269,48275,48277,48283,48293,48299,48305,48311,48313,48319,48321,48323,48327,48333,48345,48347,48355,48369,48377,48379,48383,48387,48389,48401,48403,48413,48417,48431,48433,48437,48443,48447,48453,48455,48457,48461,48463,48465,48469,48471,48481,48483,48485,48487,48495,48499,49001,49009,49013,49019,49027,49031,49045,51005,51017,51025,51029,51031,51036,51037,51043,51057,51059,51065,51071,51073,51077,51079,51083,51091,51095,51097,51101,51111,51115,51119,51121,51127,51135,51147,51155,51159,51165,51167,51171,51173,51181,51183,51191,51197,51530,51590,51610,51620,51670,51678,51720,51735,51750,51770,51810,51820,53013,53019,53023,53031,53033,53037,53039,53041,53047,53065,53069,53071,53075,54013,54019,54025,54031,54033,54041,54049,54055,54057,54063,54067,54071,54077,54079,54085,54089,54103,55001,55003,55005,55007,55011,55017,55021,55025,55029,55037,55043,55047,55049,55051,55061,55065,55067,55075,55077,55091,55097,55101,55103,55109,55117,55123,55125,55127,56007,56009,56011,56015,56017,56019,56021,56027,56031,56037,56043,56045,\n",
    "12061,  6095, 49025, 18073, 29029, 29097, 48419, 51830, 30067, 26095, 18159, 32001, 54065, 54027, 13043, 48177, 55069, 48137, 30087, 29007, 13055, 48295, 28157, 29037, 45061, 22053, 13199, 47171, 53001, 55041, 51195, 18127, 29151, 48307, 51009, 16047, 29133,  5145, 17175, 21027, 48357, 29179, 13023, 16077, 48371, 21057, 16039, 21143, 48435, 48317, 48475,  5129, 36041, 48075, 29017, 47175, 39167, 47109, 17189, 17173, 28009, 39027, 48133, 18129, 48217, 40081, 36021,  6005, 42099, 18051, 36055, 53051, 6109, 21073, 27019,  6051, 48055,  8083, 48503, 17021, 10003, 41061, 22001, 22011, 21205, 48223, 51103, 51047, 16069, 17033, 41011,  6035, 47145, 27083, 18165, 36055, 12001, 26159,  8125, 34017,\n",
    "28141, 55119, 48405, 40029, 18125, 21135, 29073, 55115, 37149,55039, 26029, 12099, 13251, 48421, 39007, 41043, 22015, 37115,54099, 51137, 22049, 55131, 17159, 56001, 40005, 18017, 28091,47101, 27037, 29005, 13239, 21019, 55085, 48253, 51139, 40101,13283, 18049, 39163, 45049, 51113,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train-valid split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for train set split\n",
    "ACT_THR = 1.8\n",
    "ABS_THR = 1.00\n",
    "\n",
    "raw['ypred_last'] = np.nan\n",
    "raw['ypred'] = np.nan\n",
    "raw['k'] = 1.\n",
    "VAL = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish paramx_xgb initialization\n"
     ]
    }
   ],
   "source": [
    "####################################################################################parameters placeholder\n",
    "#https://xgboost.readthedocs.io/en/stable/parameter.html#general-parameters\n",
    "params_general ={'booster': 'gbtree', 'verbosity':0, 'validate_parameters': 1}\n",
    "\n",
    "#https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster\n",
    "params_booster ={\n",
    "    'learning_rate': 0.3,#check\n",
    "    'min_split_loss': 0, #gamma. check\n",
    "    'max_depth': 6,#check\n",
    "    'min_child_weight': 1, #instance weight (hessian). check\n",
    "    'subsample': 0.8,#check\n",
    "    'colsample_bytree': 1,#check\n",
    "    'reg_lambda': 1,#L2 regularization term on weights\n",
    "    'reg_alpha': 0, #L1 regularization term on weights\n",
    "    'max_delta_step': 0,\n",
    "    'scale_pos_weight': 1,\n",
    "    'tree_method': 'gpu_hist', #hist\n",
    "    'predictor': 'gpu_predictor',\n",
    "    'num_parallel_tree': 1\n",
    "}\n",
    "#https://xgboost.readthedocs.io/en/stable/parameter.html#learning-task-parameters\n",
    "params_learning={\n",
    "    'objective': 'reg:pseudohubererror', 'eval_metric': 'mae',\n",
    "    'base_score': 0.5, 'seed': 2021\n",
    "}\n",
    "\n",
    "#https://xgboost.readthedocs.io/en/stable/parameter.html#command-line-parameters\n",
    "params_train={\n",
    "    'num_boost_round':500, #alias as 'n_estimators' in sklearn api\n",
    "    'early_stopping_rounds':50, 'verbose_eval':False\n",
    "}\n",
    "\n",
    "params_xgb = {**params_general, **params_booster, **params_learning}\n",
    "\n",
    "print(\"finish paramx_xgb initialization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##core tuning cv function\n",
    "def tune_para(search_params, dtrain, skip_pre=False):\n",
    "    c=0\n",
    "    for psets in search_params:\n",
    "        params_xgb.update(psets)\n",
    "        c+=1\n",
    "        if skip_pre:\n",
    "            if psets in [s[2] for s in params_xgb_prescore]:\n",
    "                print(f'skipping this cv batch {c}/{len(search_params)}')\n",
    "                continue\n",
    "        result=xgb.cv(params_xgb, dtrain, \n",
    "            num_boost_round=params_train['num_boost_round'], \n",
    "            nfold=5,\n",
    "            metrics=['mae'], \n",
    "            seed=0,verbose_eval=False,as_pandas=True,\n",
    "            shuffle=False,\n",
    "            early_stopping_rounds=params_train['early_stopping_rounds'])\n",
    "        #best score among num_boost_round\n",
    "        psets_score = (round(result['test-mae-mean'].min(),7),result.shape[0], psets)\n",
    "        params_xgb_prescore.append(psets_score)\n",
    "        print(f\"finished {c}/{len(search_params)}\")\n",
    "    return params_xgb_prescore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = {\n",
    "    'learning_rate': [i/100 for i in range(30,51,10)],\n",
    "    'max_depth': [6,10],\n",
    "    'subsample' : [i/100 for i in range(70,81,10)],\n",
    "    'colsample_bytree' : [i/100 for i in range(50,81,10)],\n",
    "    'min_child_weight' : [i/100 for i in range(100,201,10)],\n",
    "    'reg_lambda' : [i/100 for i in range(100,301,20)] ,\n",
    "    'reg_alpha' : [i/100 for i in range(40,201,20)]\n",
    "}\n",
    "search_params = list(ParameterSampler(param_distributions = gridsearch_params, n_iter = num_pset))\n",
    "#search_params = list(ParameterGrid(param_grid = gridsearch_params))\n",
    "if params_xgb_prebest in search_params:\n",
    "    pass\n",
    "else:\n",
    "    search_params.append(params_xgb_prebest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature engineering\n",
      "['state_i', 'mbd_lag_1', 'act_lag_1', 'mbd_lag_2', 'act_lag_2', 'mbd_lag_3', 'act_lag_3', 'mbd_rollmea2_1', 'mbd_rollmea4_1', 'mbd_rollmea6_1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_0/sgv1wmb92l11hndgfl0tyvjr0000gn/T/ipykernel_78026/3042571400.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(axis = 0, inplace= True)\n"
     ]
    }
   ],
   "source": [
    "## use full train set to fit\n",
    "TS = 38 # use full train set\n",
    "# Build Features based in lag of target\n",
    "print(build_features.__doc__)\n",
    "raw, feats = build_features(raw, 'target', 'active', lags = 4)\n",
    "features = ['state_i']\n",
    "features += feats\n",
    "print(features)\n",
    "\n",
    "# train two same model and take average output\n",
    "\n",
    "train_indices = (raw.istest==0) & (raw.dcount  < TS) & (raw.dcount >= 1) & (raw.lastactive>ACT_THR)  & (raw.lasttarget>ABS_THR) \n",
    "valid_indices = (raw.dcount == TS)\n",
    "df = raw.loc[train_indices]\n",
    "df.dropna(axis = 0, inplace= True)\n",
    "\n",
    "dtrain=xgb.DMatrix(df[features],label=df['target'].clip(-0.0044, 0.0046),enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_i</th>\n",
       "      <th>mbd_lag_1</th>\n",
       "      <th>act_lag_1</th>\n",
       "      <th>mbd_lag_2</th>\n",
       "      <th>act_lag_2</th>\n",
       "      <th>mbd_lag_3</th>\n",
       "      <th>act_lag_3</th>\n",
       "      <th>mbd_rollmea2_1</th>\n",
       "      <th>mbd_rollmea4_1</th>\n",
       "      <th>mbd_rollmea6_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.020489</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>0.059265</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0.038777</td>\n",
       "      <td>0.048878</td>\n",
       "      <td>0.048878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.020489</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>0.059265</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-0.020489</td>\n",
       "      <td>0.048878</td>\n",
       "      <td>0.048878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.008066</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.020489</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-0.008066</td>\n",
       "      <td>0.030711</td>\n",
       "      <td>0.040812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.020129</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-0.008066</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-0.028195</td>\n",
       "      <td>-0.048683</td>\n",
       "      <td>0.020683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.008217</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.020129</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-0.008066</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-0.011912</td>\n",
       "      <td>-0.019978</td>\n",
       "      <td>0.018799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147331</th>\n",
       "      <td>50</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.030406</td>\n",
       "      <td>0.024865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147332</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.030406</td>\n",
       "      <td>0.004457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147333</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.030406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147334</th>\n",
       "      <td>50</td>\n",
       "      <td>-0.009901</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.009901</td>\n",
       "      <td>0.010301</td>\n",
       "      <td>0.020505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147335</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.009901</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.009901</td>\n",
       "      <td>-0.009901</td>\n",
       "      <td>0.010301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100940 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        state_i  mbd_lag_1  act_lag_1  mbd_lag_2  act_lag_2  mbd_lag_3  \\\n",
       "3             0  -0.020489      -26.0   0.059265       45.0   0.010101   \n",
       "4             0   0.000000        0.0  -0.020489      -26.0   0.059265   \n",
       "5             0  -0.008066       -1.0   0.000000       -1.0  -0.020489   \n",
       "6             0  -0.020129      -25.0  -0.008066      -26.0   0.000000   \n",
       "7             0   0.008217       10.0  -0.020129      -15.0  -0.008066   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "147331       50   0.020202        2.0   0.000000        2.0   0.010204   \n",
       "147332       50   0.000000        0.0   0.020202        2.0   0.000000   \n",
       "147333       50   0.000000        0.0   0.000000        0.0   0.020202   \n",
       "147334       50  -0.009901       -1.0   0.000000       -1.0   0.000000   \n",
       "147335       50   0.000000        0.0  -0.009901       -1.0   0.000000   \n",
       "\n",
       "        act_lag_3  mbd_rollmea2_1  mbd_rollmea4_1  mbd_rollmea6_1  \n",
       "3            -6.0        0.038777        0.048878        0.048878  \n",
       "4            45.0       -0.020489        0.048878        0.048878  \n",
       "5           -27.0       -0.008066        0.030711        0.040812  \n",
       "6           -26.0       -0.028195       -0.048683        0.020683  \n",
       "7           -16.0       -0.011912       -0.019978        0.018799  \n",
       "...           ...             ...             ...             ...  \n",
       "147331        3.0        0.020202        0.030406        0.024865  \n",
       "147332        2.0        0.020202        0.030406        0.004457  \n",
       "147333        2.0        0.000000        0.020202        0.030406  \n",
       "147334       -1.0       -0.009901        0.010301        0.020505  \n",
       "147335       -1.0       -0.009901       -0.009901        0.010301  \n",
       "\n",
       "[100940 rows x 10 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = raw.loc[train_indices]\n",
    "df[features].dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start tuning\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[11:48:00] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x000000014b443c34 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n  [bt] (1) 2   libxgboost.dylib                    0x000000014b4e5180 xgboost::gbm::GBTree::ConfigureUpdaters() + 424\n  [bt] (2) 3   libxgboost.dylib                    0x000000014b4e4d78 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > > const&) + 952\n  [bt] (3) 4   libxgboost.dylib                    0x000000014b500a20 xgboost::LearnerConfiguration::Configure() + 1016\n  [bt] (4) 5   libxgboost.dylib                    0x000000014b4471a0 XGBoosterBoostedRounds + 104\n  [bt] (5) 6   libffi.8.dylib                      0x00000001037c804c ffi_call_SYSV + 76\n  [bt] (6) 7   libffi.8.dylib                      0x00000001037c574c ffi_call_int + 1208\n  [bt] (7) 8   _ctypes.cpython-310-darwin.so       0x00000001037a8bb8 _ctypes_callproc + 1236\n  [bt] (8) 9   _ctypes.cpython-310-darwin.so       0x00000001037a2e38 PyCFuncPtr_call + 1160\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mif\u001b[39;00m tunepara:\n\u001b[1;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mStart tuning\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     params_xgb_score\u001b[39m=\u001b[39mtune_para(search_params,dtrain,skip_pre \u001b[39m=\u001b[39;49m skipping_pre)\n\u001b[1;32m      5\u001b[0m     \u001b[39mdel\u001b[39;00m dtrain\n\u001b[1;32m      6\u001b[0m     gc\u001b[39m.\u001b[39mcollect()\n",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m, in \u001b[0;36mtune_para\u001b[0;34m(search_params, dtrain, skip_pre)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mskipping this cv batch \u001b[39m\u001b[39m{\u001b[39;00mc\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(search_params)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m result\u001b[39m=\u001b[39mxgb\u001b[39m.\u001b[39;49mcv(params_xgb, dtrain, \n\u001b[1;32m     12\u001b[0m     num_boost_round\u001b[39m=\u001b[39;49mparams_train[\u001b[39m'\u001b[39;49m\u001b[39mnum_boost_round\u001b[39;49m\u001b[39m'\u001b[39;49m], \n\u001b[1;32m     13\u001b[0m     nfold\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m     14\u001b[0m     metrics\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mmae\u001b[39;49m\u001b[39m'\u001b[39;49m], \n\u001b[1;32m     15\u001b[0m     seed\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,verbose_eval\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,as_pandas\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     16\u001b[0m     shuffle\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     17\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mparams_train[\u001b[39m'\u001b[39;49m\u001b[39mearly_stopping_rounds\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     18\u001b[0m \u001b[39m#best score among num_boost_round\u001b[39;00m\n\u001b[1;32m     19\u001b[0m psets_score \u001b[39m=\u001b[39m (\u001b[39mround\u001b[39m(result[\u001b[39m'\u001b[39m\u001b[39mtest-mae-mean\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmin(),\u001b[39m7\u001b[39m),result\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], psets)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/xgboost/training.py:507\u001b[0m, in \u001b[0;36mcv\u001b[0;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle, custom_metric)\u001b[0m\n\u001b[1;32m    499\u001b[0m callbacks \u001b[39m=\u001b[39m callback\u001b[39m.\u001b[39mCallbackContainer(\n\u001b[1;32m    500\u001b[0m     callbacks,\n\u001b[1;32m    501\u001b[0m     metric\u001b[39m=\u001b[39mmetric_fn,\n\u001b[1;32m    502\u001b[0m     is_cv\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    503\u001b[0m     output_margin\u001b[39m=\u001b[39mcallable(obj) \u001b[39mor\u001b[39;00m metric_fn \u001b[39mis\u001b[39;00m feval,\n\u001b[1;32m    504\u001b[0m )\n\u001b[1;32m    506\u001b[0m booster \u001b[39m=\u001b[39m _PackedBooster(cvfolds)\n\u001b[0;32m--> 507\u001b[0m callbacks\u001b[39m.\u001b[39;49mbefore_training(booster)\n\u001b[1;32m    509\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_boost_round):\n\u001b[1;32m    510\u001b[0m     \u001b[39mif\u001b[39;00m callbacks\u001b[39m.\u001b[39mbefore_iteration(booster, i, dtrain, \u001b[39mNone\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/xgboost/callback.py:147\u001b[0m, in \u001b[0;36mCallbackContainer.before_training\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''Function called before training.'''\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m--> 147\u001b[0m     model \u001b[39m=\u001b[39m c\u001b[39m.\u001b[39;49mbefore_training(model\u001b[39m=\u001b[39;49mmodel)\n\u001b[1;32m    148\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbefore_training should return the model\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    149\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_cv:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/xgboost/callback.py:349\u001b[0m, in \u001b[0;36mEarlyStopping.before_training\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbefore_training\u001b[39m(\u001b[39mself\u001b[39m, model):\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstarting_round \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mnum_boosted_rounds()\n\u001b[1;32m    350\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/xgboost/training.py:248\u001b[0m, in \u001b[0;36m_PackedBooster.num_boosted_rounds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnum_boosted_rounds\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    247\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Number of boosted rounds.'''\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcvfolds[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mnum_boosted_rounds()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/xgboost/training.py:206\u001b[0m, in \u001b[0;36mCVPack.__getattr__.<locals>._inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_inner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 206\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbst, name)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/xgboost/core.py:2274\u001b[0m, in \u001b[0;36mBooster.num_boosted_rounds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2272\u001b[0m rounds \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int()\n\u001b[1;32m   2273\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2274\u001b[0m _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterBoostedRounds(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, ctypes\u001b[39m.\u001b[39;49mbyref(rounds)))\n\u001b[1;32m   2275\u001b[0m \u001b[39mreturn\u001b[39;00m rounds\u001b[39m.\u001b[39mvalue\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/xgboost/core.py:203\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \n\u001b[1;32m    194\u001b[0m \u001b[39mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39m    return value from API calls\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[39mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[39m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [11:48:00] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x000000014b443c34 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n  [bt] (1) 2   libxgboost.dylib                    0x000000014b4e5180 xgboost::gbm::GBTree::ConfigureUpdaters() + 424\n  [bt] (2) 3   libxgboost.dylib                    0x000000014b4e4d78 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > > const&) + 952\n  [bt] (3) 4   libxgboost.dylib                    0x000000014b500a20 xgboost::LearnerConfiguration::Configure() + 1016\n  [bt] (4) 5   libxgboost.dylib                    0x000000014b4471a0 XGBoosterBoostedRounds + 104\n  [bt] (5) 6   libffi.8.dylib                      0x00000001037c804c ffi_call_SYSV + 76\n  [bt] (6) 7   libffi.8.dylib                      0x00000001037c574c ffi_call_int + 1208\n  [bt] (7) 8   _ctypes.cpython-310-darwin.so       0x00000001037a8bb8 _ctypes_callproc + 1236\n  [bt] (8) 9   _ctypes.cpython-310-darwin.so       0x00000001037a2e38 PyCFuncPtr_call + 1160\n\n"
     ]
    }
   ],
   "source": [
    "##############################start tuning and update params_xgb, logging ,setup skipping_pre_feature\n",
    "if tunepara:\n",
    "    print('Start tuning')\n",
    "    params_xgb_score=tune_para(search_params,dtrain,skip_pre = skipping_pre)\n",
    "    del dtrain\n",
    "    gc.collect()\n",
    "    ##score ranking rules min: rmse,min_child_weight,learning_rate,reg_alpha\n",
    "    params_xgb_score.sort(key=lambda x: (x[0],x[2]['min_child_weight'],x[2]['learning_rate'],x[2]['reg_alpha']))\n",
    "    params_xgb.update(params_xgb_score[0][2])\n",
    "    \n",
    "    with open(f\"{PRE_MOD_FOLDER}/model_nof_{params_version}/params_xgb_score{params_version}\", \"wb\") as fp:   \n",
    "        pickle.dump(params_xgb_score, fp)\n",
    "    with open(f\"{PRE_MOD_FOLDER}/model_nof_{params_version}/params_xgb_best{params_version}\", 'wb') as f: \n",
    "        pickle.dump(params_xgb_score[0][2],f)\n",
    "    if params_xgb_score[0][2] == params_xgb_prebest:\n",
    "        print('best params_xgb does not change!')\n",
    "        skipping_pre_feature = True\n",
    "    else:\n",
    "        print('best params_xgb differs!')\n",
    "        skipping_pre_feature = False\n",
    "        feature_prescore = []\n",
    "elif params_xgb_prebest is not None:\n",
    "    params_xgb.update(params_xgb_prebest)\n",
    "    \n",
    "    with open(f\"{PRE_MOD_FOLDER}/model_nof_{params_version}/params_xgb_score{params_version}\", \"wb\") as fp:   \n",
    "        pickle.dump(params_xgb_prescore, fp)\n",
    "    with open(f\"{PRE_MOD_FOLDER}/model_nof_{params_version}/params_xgb_best{params_version}\", 'wb') as f: \n",
    "        pickle.dump(params_xgb_prebest,f)\n",
    "    skipping_pre_feature = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model0.fit(\n",
    "    raw.loc[train_indices, features],\n",
    "    raw.loc[train_indices, 'target'].clip(-0.0044, 0.0046),\n",
    ")\n",
    "\n",
    "ypred = (model0.predict(raw.loc[valid_indices, features]) + model1.predict(raw.loc[valid_indices, features]))/2\n",
    "raw.loc[valid_indices, 'k'] = ypred + 1.\n",
    "raw.loc[valid_indices,'k'] = raw.loc[valid_indices,'k'] * raw.loc[valid_indices,'microbusiness_density']\n",
    "\n",
    "# Validate\n",
    "lastval = raw.loc[raw.dcount==TS, ['cfips', 'microbusiness_density']].set_index('cfips').to_dict()['microbusiness_density']\n",
    "dt = raw.loc[raw.dcount==TS, ['cfips', 'k']].set_index('cfips').to_dict()['k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
